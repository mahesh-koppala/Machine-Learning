{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please note that the first code cell took almost 10 minutes to run on my computer, I suppose it was because my computer \n",
    "#is old.\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup  \n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics , model_selection\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#this function processes all the text files and converts into a csv file with two fields: review and score. A score of\n",
    "#-1 is given to a negative review and a score of 1 is given to a positive review\n",
    "def convertToCSV(reviews, data_path_neg, data_path_pos):\n",
    "    with open(reviews, 'w') as f:\n",
    "        neg_rev_path = os.listdir(data_path_neg)\n",
    "        pos_rev_path = os.listdir(data_path_pos)\n",
    "        output = csv.writer(f)\n",
    "        output.writerow(['review', 'score'])\n",
    "\n",
    "        for each in neg_rev_path:\n",
    "            with open(data_path_neg + '/' + each, 'rb') as txt_f:\n",
    "                output.writerow([txt_f.read(), -1])\n",
    "                txt_f.close()\n",
    "        for each in pos_rev_path:\n",
    "            with open(data_path_pos + '/' + each, 'rb') as txt_f:\n",
    "                output.writerow([txt_f.read(), 1])\n",
    "                txt_f.close()\n",
    "\n",
    "\n",
    "        f.close()\n",
    "    return reviews\n",
    "\n",
    "#the given data is split into training and testing data sets\n",
    "def splitData(train_reviews, test_reviews):\n",
    "    df_train = pd.read_csv(train_reviews)\n",
    "    df_train.head()\n",
    "    #print(df_train['review'][2500])\n",
    "    df_test = pd.read_csv(test_reviews)\n",
    "    df_test.head()\n",
    "    #print(df_test['review'][2500])\n",
    "    X_train = df_train.iloc[:,:-1]\n",
    "    y_train = df_train.iloc[:,-1]\n",
    "    X_test = df_test.iloc[:,:-1]\n",
    "    y_test = df_test.iloc[:,-1]\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "#This is a function which takes in the raw movie review as argument and spits out a clean sequence of words by removing html\n",
    "#tags, stop words, any non letter characters, and converts to lower case.\n",
    "def data_cleaning(movie_review):\n",
    "    soup = BeautifulSoup(movie_review)\n",
    "    text = soup.get_text()\n",
    "    #print(text)\n",
    "    text = re.sub('[^a-z\\s]',\" \", text.lower())\n",
    "    clean_words = text.split()\n",
    "    stop_words_set = set(stopwords.words(\"english\"))\n",
    "    stop_words_set.add('b')\n",
    "    #print(stop_words_set)\n",
    "    clean_words = [w for w in clean_words if not w in stop_words_set]\n",
    "    return \" \".join(clean_words)\n",
    "\n",
    "#this function applies data cleaning to each and every row of the data and converts into a list\n",
    "def processedReviews(splittedData):\n",
    "    processed_reviews = []\n",
    "    for i in range(splittedData['review'].size):\n",
    "        processed_reviews.append(data_cleaning(splittedData[\"review\"][i]))\n",
    "    return processed_reviews\n",
    "\n",
    "#this is a function to create Bag of words model\n",
    "def bowVectorizer(processed_train_reviews, processed_test_reviews):\n",
    "    vectorizer_bow = CountVectorizer(analyzer = \"word\", max_features = 5000)\n",
    "    train_featVec_bow = vectorizer_bow.fit_transform(processed_train_reviews)\n",
    "    train_featVec_bow = train_featVec_bow.toarray()\n",
    "    #type(train_featVec_bow)\n",
    "    #print(train_feature_vectors[2500])\n",
    "    test_featVec_bow = vectorizer_bow.transform(processed_test_reviews)\n",
    "    test_featVec_bow = test_featVec_bow.toarray()\n",
    "    return train_featVec_bow, test_featVec_bow\n",
    "\n",
    "#this is a function for Tfidf\n",
    "def tfidfVectorizer(processed_train_reviews, processed_test_reviews):\n",
    "    vectorizer_tfidf = TfidfVectorizer(min_df = 5,max_df = 0.8,sublinear_tf = True,use_idf = True)\n",
    "    train_featVec_tfidf = vectorizer_tfidf.fit_transform(processed_train_reviews)\n",
    "    test_featVec_tfidf = vectorizer_tfidf.transform(processed_test_reviews)\n",
    "    return train_featVec_tfidf, test_featVec_tfidf\n",
    "\n",
    "#this function gives the accuracy of Naive Bayes classifier\n",
    "def naiveBayes(train_featVec, test_featVec):\n",
    "    model = MultinomialNB()\n",
    "    model.fit(train_featVec, y_train)\n",
    "    y_pred = model.predict(test_featVec)\n",
    "    return y_pred\n",
    "    \n",
    "#this function gives the accuracy of SVM classifier\n",
    "def svm(train_featVec, test_featVec):\n",
    "    model = LinearSVC()\n",
    "    model.fit(train_featVec, y_train)\n",
    "    y_pred = model.predict(test_featVec)\n",
    "    return y_pred\n",
    "    \n",
    "#this function gives the accuracy of K Nearest Neighbour classifier\n",
    "def knn(train_featVec, test_featVec):\n",
    "    model = KNeighborsClassifier(n_neighbors = 3)\n",
    "    model.fit(train_featVec_tfidf, y_train)\n",
    "    y_pred = model.predict(test_featVec_tfidf)\n",
    "    return y_pred\n",
    "    \n",
    "train_reviews = convertToCSV('train_movie_reviews.csv', 'aclImdb/train/neg', 'aclImdb/train/pos')\n",
    "test_reviews = convertToCSV('test_movie_reviews.csv', 'aclImdb/test/neg', 'aclImdb/test/pos')\n",
    "\n",
    "X_train, y_train, X_test, y_test = splitData(train_reviews, test_reviews)\n",
    "\n",
    "processed_train_reviews = processedReviews(X_train)\n",
    "processed_test_reviews = processedReviews(X_test)\n",
    "\n",
    "train_featVec_bow, test_featVec_bow = bowVectorizer(processed_train_reviews, processed_test_reviews)\n",
    "train_featVec_tfidf, test_featVec_tfidf = tfidfVectorizer(processed_train_reviews, processed_test_reviews)\n",
    "\n",
    "nb_y_pred = naiveBayes(train_featVec_bow, test_featVec_bow)\n",
    "#print(\"one\")\n",
    "svm_y_pred = svm(train_featVec_tfidf, test_featVec_tfidf)\n",
    "#print(\"two\")\n",
    "knn_y_pred = knn(train_featVec_tfidf, test_featVec_tfidf)\n",
    "#print(\"three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Naive Bayes: 0.84\n",
      "Accuracy of SVM: 0.87\n",
      "Accuracy of KNN: 0.67\n"
     ]
    }
   ],
   "source": [
    "#We will now evaluate the performance of all the three classifiers using the following methods\n",
    "\n",
    "#First is the simple one, which is accuracy and it just says how often the classifier is correct\n",
    "nb_accuracy = metrics.accuracy_score(y_test, nb_y_pred)\n",
    "print('Accuracy of Multinomial Naive Bayes: {:.2f}'.format(nb_accuracy))\n",
    "\n",
    "svm_accuracy = metrics.accuracy_score(y_test, svm_y_pred)\n",
    "print('Accuracy of SVM: {:.2f}'.format(svm_accuracy))\n",
    "\n",
    "knn_accuracy = metrics.accuracy_score(y_test, knn_y_pred)\n",
    "print('Accuracy of KNN: {:.2f}'.format(knn_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrxi of Multinomial Naive Bayes is  [[10828  1672]\n",
      " [ 2346 10154]]\n",
      "Accuracy of confusion matrix for Multinomial Naive Bayes is  0.83928\n",
      "\n",
      "\n",
      "Confusion matrxi of SVM is  [[11041  1459]\n",
      " [ 1705 10795]]\n",
      "Accuracy of confusion matrix for SVM is  0.87344\n",
      "\n",
      "\n",
      "Confusion matrxi of KNN is  [[8606 3894]\n",
      " [4242 8258]]\n",
      "Accuracy of confusion matrix for KNN is  0.67456\n"
     ]
    }
   ],
   "source": [
    "#Second method is the confusion matrix\n",
    "nb_cm = confusion_matrix(y_test, nb_y_pred)\n",
    "print(\"Confusion matrxi of Multinomial Naive Bayes is \",nb_cm)\n",
    "print(\"Accuracy of confusion matrix for Multinomial Naive Bayes is \", (nb_cm[0,0]+nb_cm[1,1])/np.sum(nb_cm))\n",
    "print(\"\\n\")\n",
    "svm_cm = confusion_matrix(y_test, svm_y_pred)\n",
    "print(\"Confusion matrxi of SVM is \",svm_cm)\n",
    "print(\"Accuracy of confusion matrix for SVM is \", (svm_cm[0,0]+svm_cm[1,1])/np.sum(svm_cm))\n",
    "print(\"\\n\")\n",
    "knn_cm = confusion_matrix(y_test, knn_y_pred)\n",
    "print(\"Confusion matrxi of KNN is \",knn_cm)\n",
    "print(\"Accuracy of confusion matrix for KNN is \", (knn_cm[0,0]+knn_cm[1,1])/np.sum(knn_cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of Multinomial Naive Bayes is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.87      0.84     12500\n",
      "           1       0.86      0.81      0.83     12500\n",
      "\n",
      "    accuracy                           0.84     25000\n",
      "   macro avg       0.84      0.84      0.84     25000\n",
      "weighted avg       0.84      0.84      0.84     25000\n",
      "\n",
      "\n",
      "\n",
      "Report of SVM is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.88      0.87     12500\n",
      "           1       0.88      0.86      0.87     12500\n",
      "\n",
      "    accuracy                           0.87     25000\n",
      "   macro avg       0.87      0.87      0.87     25000\n",
      "weighted avg       0.87      0.87      0.87     25000\n",
      "\n",
      "\n",
      "\n",
      "Report of KNN is \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.69      0.68     12500\n",
      "           1       0.68      0.66      0.67     12500\n",
      "\n",
      "    accuracy                           0.67     25000\n",
      "   macro avg       0.67      0.67      0.67     25000\n",
      "weighted avg       0.67      0.67      0.67     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Third is Precision, recall and f1-score\n",
    "print(\"Report of Multinomial Naive Bayes is \")\n",
    "print(classification_report(y_test, nb_y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Report of SVM is \")\n",
    "print(classification_report(y_test, svm_y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Report of KNN is \")\n",
    "print(classification_report(y_test, knn_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
